{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generic_FFNN_Class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrldTQg1FDCJuVyfnFQ5f9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiramangit/Imag_reco/blob/master/Generic_FFNN_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZsjUEnD0nE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.metrics import log_loss,mean_squared_error,accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly95BzNtYd1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data,labels = make_blobs(1000,2,centers=4,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ1NU8cYZIV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(data[:,0],data[:,1],c = labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxg3VXAFYew_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(data,labels,stratify=labels,random_state=1)\n",
        "print(X_train.shape,Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vrU1lwYZcvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## One Hot Encoding\n",
        "enc = OneHotEncoder()\n",
        "\n",
        "Y_OH_train = enc.fit_transform(np.expand_dims(Y_train,axis=1)).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udoOR8xf2Cv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generic_vectorized_FFNN:\n",
        "  def __init__(self,X,layer_info,output_function='SoftMax'):\n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "\n",
        "    self.nl = len(layer_info)\n",
        "    self.layer_info = layer_info\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "\n",
        "    self.dA = {}\n",
        "    self.dH = {}\n",
        "    self.dW = {}\n",
        "    self.dB = {}\n",
        "\n",
        "\n",
        "    self.W[1] = np.random.randn(X.shape[1], self.layer_info[0])\n",
        "    self.B[1] = np.random.rand(1, self.layer_info[0])\n",
        "    self.A[0] = X\n",
        "    self.H[0] = X\n",
        "\n",
        "    for i in range(1,self.nl):\n",
        "      self.W[i+1] = np.random.randn(self.layer_info[i-1], self.layer_info[i])\n",
        "      self.B[i+1] = np.random.randn(1, self.layer_info[i])\n",
        "\n",
        "\n",
        "  def sigmoid(self,X):\n",
        "    return 1.0/(1.0+np.exp(-X))\n",
        "\n",
        "  def softmax(self,X):\n",
        "    exps = np.exp(X)\n",
        "    summ = np.sum(exps,axis=1).reshape(-1,1)\n",
        "    ret = exps/summ\n",
        "    return ret\n",
        "\n",
        "  def forward_pass(self,X):\n",
        "\n",
        "    for i in range(self.nl):\n",
        "      self.A[i+1] = np.matmul(self.A[i],self.W[i+1]) + self.B[i+1]   # (N,c) * (c,n) -> (N,n)\n",
        "      if i==len( self.layer_info)-1:\n",
        "        self.H[i+1] = self.softmax(self.A[i+1])\n",
        "        return self.H[i+1]\n",
        "      else:\n",
        "        self.H[i+1] = self.sigmoid(self.A[i+1])     # (N,n)\n",
        "  \n",
        "  def grad_sigmoid(self,X):\n",
        "    return X*(1-X)\n",
        "\n",
        "  def grad_params(self,X,Y):\n",
        "    self.forward_pass(X)\n",
        "\n",
        "    self.dA[self.nl] = self.H[self.nl] - Y     # (N,2)\n",
        "  \n",
        "    ## Output Layer \n",
        "    for i in range(self.nl-1,-1,-1):\n",
        "      self.dW[i+1] = np.matmul(self.H[i].T,self.dA[i+1])     # (2,N)*(N,n) -> (2,n)\n",
        "      self.dB[i+1] = np.sum(self.dA[i+1],axis=0)\n",
        "\n",
        "      \n",
        "      if i!=0:\n",
        "        self.dH[i] = np.matmul(self.dA[i+1],self.W[i+1].T) \n",
        "        self.dA[i] = np.multiply(self.dH[i],self.grad_sigmoid(self.H[i]))\n",
        "\n",
        "  def fit(self,X,Y,epochs= 1, learning_rate= 1 ,display_loss = False):\n",
        "\n",
        "    if display_loss == True :\n",
        "      loss = {}\n",
        "    \n",
        "    for ind in tqdm_notebook(range(epochs),total = epochs, unit='epoch'):\n",
        "      self.grad_params(X,Y)\n",
        "      m = X.shape[0]\n",
        "      for i in range(1,self.nl):\n",
        "        self.W[i] -= learning_rate*(self.dW[i]/m)\n",
        "        self.B[i] -= learning_rate*(self.dB[i]/m)\n",
        "\n",
        "\n",
        "      if display_loss==True:\n",
        "        Y_pred = self.predict(X)\n",
        "        Y_val = np.argmax(Y,axis=1)\n",
        "        Y_pred_val = np.argmax(Y_pred,axis=1)\n",
        "        loss_val = mean_squared_error(Y_val,Y_pred_val)\n",
        "        loss[ind] = loss_val\n",
        "\n",
        "    loss_list = list(loss.values())\n",
        "\n",
        "    if display_loss == True:\n",
        "      \n",
        "      plt.plot(loss_list,'*')\n",
        "      plt.xlabel('epoch')\n",
        "      plt.ylabel('mean loss')     \n",
        "      plt.show()\n",
        "\n",
        "  def predict(self, X):\n",
        "    Y_pred = self.forward_pass(X)\n",
        "    return np.array(Y_pred).squeeze()\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtxhgBUKvfpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obj = Generic_vectorized_FFNN(X_train,[2,3,4])\n",
        "ret = obj.fit(X_train,Y_OH_train,epochs=4000,learning_rate=0.05,display_loss=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvoi4zGth3W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_train = obj.predict(X_train)\n",
        "Y_pred_vals_train = np.argmax(Y_pred_train,axis=1)\n",
        "\n",
        "Y_train_val = np.argmax(Y_OH_train,axis=1)\n",
        "#Y_pred_test = obj.predict(X_test)\n",
        "#Y_pred_vals_test = np.argmax(Y_pred_test,axis=1)\n",
        "\n",
        "train_accuracy = accuracy_score(Y_pred_vals_train,Y_train_val)\n",
        "#test_accuracy = accuracy_score(Y_pred_vals_test,Y_test)\n",
        "\n",
        "print(\"train_accuracy\",train_accuracy)\n",
        "#print(\"test accuracy\",test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CQz8hW5jPsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X_train[:,0], X_train[:,1], c=Y_train, s=15*(np.abs(np.sign(Y_pred_vals_train-Y_train))+.1))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}